[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "karl vilgot hubertus vilhelmsson emneby :-)",
    "section": "",
    "text": "I’ve spent most of my life on understanding the foundations of the physical world.\nI’ll spend the rest on how models think and how to make them better and safer.\nI believe that fundamental physics is an attempt at approximating the universe’s source code, and that AI will probably find it.1\nThis is exciting, and on this website, I will explore the basics of deep learning.\nFeel free to reach out at the correct reordering of either of the following 2 sets of strings: “berkeley”, “@”, “.”, “edu”, “karlcal”, or “slac.stanford”, “@”, “karlcal”, “.”, “edu”"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "karl vilgot hubertus vilhelmsson emneby :-)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf new ideas are clever combinations of previous ideas, it seems that artificial neural networks will be the ones coming up with most new theories and inventions by virtue of their computational speed.\nEven Einstein, arguably the smartest person ever, got special relativity by combining Galilean relativity, the absence of an ether (as implied by the recently conducted Michelson-Morley experiment), and a fixed speed of light as given by the solution to Maxwell’s equations. As far as I can tell, all new “idea vectors” are constructed from previous “idea vectors” in some fixed-dimensional space.↩︎"
  }
]